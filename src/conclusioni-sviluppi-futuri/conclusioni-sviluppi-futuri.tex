\chapter{Conclusioni e Sviluppi Futuri}

In questo capitolo conclusivo vengono riassunti i risultati ottenuti dal lavoro di ricerca e sviluppo svolto, evidenziando il raggiungimento degli obbiettivi preposti.\
Successivamente, vengono delineate le possibili direzioni future per estendere e migliorare l'approccio proposto,\
con particolare attenzione all'integrazione dei dati e all'adozione di architetture di apprendimento più complesse.

\section{Conclusioni}

Il presente lavoro di tesi ha affrontato il problema della classificazione di \textit{Malware} in ambiente \textit{Windows} attraverso lo studio delle sequenze di chiamate API e l'utilizzo di tecniche di Machine Learning.
L'obiettivo principale del lavoro di tesi è quello di sviluppare un sistema che attraverso l'utilizzo di approcci basati su Machine Learning è in grado classificare applicazioni sviluppate per ambienti Windows in software benigno o malevolo.
In particolare, il sistema sviluppato nel progetto di tesi è stato valutato sia per compiti di classificazione binaria (software benigno o malevolo) sia per compiti di classificazione multiclasse (classificazione in diverse famiglie di software malevolo).
La prima fase della tesi ha visto lo sviluppo di una parte di preprocessing dei dati per standardizzare dataset eterogenei (\textit{apimds}, \textit{octack}, \textit{mpasco} e \textit{quovadis}) contenti sequenze di chiamate API.
Successivamente sono stati implementati e addestrati i due classificatori \textit{RandomForest} e \textit{XGBoost} sfruttando la rappresentazione \textit{Bag-of-Words} per la trasformazione delle sequenze in vettori delle caratteristiche.
Infine è stata effettuata una validazione empirica applicando i classificatori ai diversi dataset e analizzando le matrici di confusione risultanti, dalle quali sono state calcolate le metriche per verificarne l'efficacia.
Dall'analisi dei risultati sperimentali, emerge che l'utilizzo delle sole frequenze delle chiamate API si è dimostrato sufficiente per ottenere buone accuratezze di classificazione,\
confermando l'ipotesi che i malware tendano a utilizzare sottoinsiemi specifici e ricorrenti di funzionalità del sistema operativo per raggiungere i propri scopi.
In particolare, i risultati della valutazione empirica hanno mostrato che il modello \textit{RandomForest}  è complessivamente più accurato rispetto a \textit{XGBoost}.
Tale superiorità è risultata particolarmente evidente negli scenari multi-classe e in presenza di dataset sbilanciati (come \textit{octack} e \textit{apimds}), dove \textit{RandomForest} ha garantito una migliore generalizzazione,\
mantenendo valori alti di \fiscore{} anche sulle classi minoritarie, a differenza di \textit{XGBoost}.

In sintesi, il sistema sviluppato ha dimostrato buona capacità di identificare le minacce con precisione osservando il comportamento del software piuttosto che la sua struttura statica,\
superando così i limiti delle tecniche di offuscamento che affliggono l'analisi statica tradizionale.

\section{Sviluppi Futuri}

Un primo sviluppo naturale del lavoro svolto consiste nell'integrazione dei dataset analizzati in un unico corpus.
Nel presente studio, sebbene i dati siano stati uniformati in un formato standard comune, le fasi di addestramento e validazione sono state condotte sui singoli dataset in modo indipendente.
Una futura estensione prevede quindi la fusione effettiva di queste fonti con l'obiettivo di ottenere un unico dataset contente una maggiore quantità di dati.
Disporre di una base di dati così ampia e variegata permetterebbe di addestrare un modello ``generalista'', capace di riconoscere minacce provenienti da contesti molto diversi tra loro,
simulando più fedelmente uno scenario reale in cui i malware presentano una grande variabilità.
Tuttavia, l'unione di dataset eterogenei comporterebbe inevitabilmente un aumento esponenziale del numero di API distinte (il vocabolario), generando vettori delle caratteristiche di dimensioni enormi e contenenti per lo più valori nulli (sparsità).
Gestire uno spazio così vasto può confondere algoritmi come \textit{RandomForest} e \textit{XGBoost}, riducendone l'efficienza e aumentando i tempi di calcolo.
Per mitigare questo problema, sarà fondamentale implementare tecniche di \textbf{selezione delle caratteristiche} (\textit{Feature Selection}) più avanzate.
L'idea è quella di utilizzare metodi statistici (come l'\textit{Information Gain} o la \textit{PCA}) per identificare e mantenere solo quel sottoinsieme di API che è realmente discriminante per la classificazione, scartando tutto ciò che è rumore o ridondanza.
Questo permetterebbe di mantenere il modello leggero e performante anche su scala molto più grande.

Infine, una linea di ricerca fondamentale riguarda il superamento dei limiti strutturali del modello \textit{Bag-of-Words}.
Come evidenziato dai risultati sperimentali, l'approccio basato sulle sole frequenze si è rivelato efficace per una classificazione ad alto livello, ma soffre di un limite intrinseco: la perdita dell'informazione sequenziale.
Tale semplificazione impedisce di distinguere comportamenti che, pur utilizzando le stesse API, differiscono per l'ordine di esecuzione o per il contesto logico.
A tal proposito, un naturale sviluppo del lavoro consiste nella validazione empirica sui dataset qui proposti delle metodologie avanzate già discusse nello Stato dell'Arte.
In particolare, si suggerisce di confrontare l'attuale \textit{baseline} con approcci che preservano la struttura temporale e semantica delle tracce.
Una prima direzione prevede l'estensione al dominio multiclasse delle tecniche di analisi semantica e probabilistica introdotte da Amer e Zelinka\cite{Amer_Zelinka_2020}.
Sebbene originariamente applicato alla classificazione binaria, questo approccio — che combina proiezioni vettoriali (\textit{Word2Vec}) con catene di Markov — offrirebbe un meccanismo robusto per modellare le transizioni di stato tra le chiamate API anche nel riconoscimento delle specifiche famiglie di malware.
L'adattamento richiederebbe la costruzione di una matrice di transizione dedicata per ogni singola classe, e la classificazione finale verrebbe quindi determinata calcolando la verosimiglianza della sequenza osservata rispetto a ciascun modello e assegnando l'etichetta della classe che massimizza tale probabilità (\textit{Maximum Likelihood Estimation}).
Parallelamente, l'indagine dovrebbe estendersi verso il \textit{Deep Learning} sequenziale, sperimentando reti neurali ricorrenti e convoluzionali (RNN/CNN) adattive, come nel modello di Gond e Mohapatra\cite{Gond_Mohapatra_2025}, capaci di gestire l'evoluzione temporale delle tracce e il fenomeno del \textit{concept drift}.
Infine, un'alternativa promettente risiede nella rappresentazione a grafo, modellando le sequenze come grafi direzionali elaborati tramite \textit{Graph Convolutional Networks} (GCN) secondo la metodologia di Ma et al.\cite{10.1371/journal.pone.0299706}.
L'obiettivo di tale estensione sarebbe verificare quantitativamente se la maggiore complessità computazionale richiesta da questi modelli si traduca in un incremento significativo delle prestazioni rispetto ai risultati già solidi ottenuti con \textit{RandomForest}, specialmente nella rilevazione di varianti di malware complesse che eludono l'analisi frequenziale.