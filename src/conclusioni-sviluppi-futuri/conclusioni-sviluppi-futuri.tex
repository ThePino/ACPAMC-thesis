\chapter{Conclusioni e Sviluppi Futuri}

In questo capitolo conclusivo vengono riassunti i risultati ottenuti dal lavoro di ricerca e sviluppo svolto, evidenziando il raggiungimento degli obbiettivi preposti.\
Successivamente, vengono delineate le possibili direzioni future per estendere e migliorare l'approccio proposto,\
con particolare attenzione all'integrazione dei dati e all'adozione di architetture di apprendimento più complesse.

\section{Conclusioni}

Il presente lavoro di tesi ha affrontato il problema della classificazione di \textit{Malware} in ambiente \textit{Windows} attraverso l'analisi dinamica e l'utilizzo di tecniche di Machine Learning.
L'obiettivo principale era sviluppare un sistema in grado di distinguere non solo tra software benigno e malevolo, ma anche di categorizzare le diverse famiglie di \textit{Malware}, basandosi sulle frequenze di chiamate API.
L'approccio proposto ha previsto la standardizzazione di dataset eterogenei (\textit{apimds}, \textit{octack}, \textit{mpasco}, \textit{quovadis}) e l'implementazione dei classificatori \textit{RandomForest} e \textit{XGBoost},\
sfruttando la rappresentazione \textit{Bag-of-Words} per la trasformazione delle sequenze in vettori delle caratteristiche.
La validazione empirica è stata condotta applicando i modelli ai diversi dataset e analizzando le matrici di confusione risultanti, dalle quali sono state calcolate le metriche per verificarne l'efficacia.

Dall'analisi dei risultati sperimentali, emerge l'efficacia dell'analisi dinamica: l'utilizzo delle sole frequenze delle chiamate API si è dimostrato sufficiente per ottenere buone accuratezze di classificazione,\
confermando l'ipotesi che i malware tendano a utilizzare sottoinsiemi specifici e ricorrenti di funzionalità del sistema operativo per raggiungere i propri scopi.
Nel confronto diretto, \textit{RandomForest} si è dimostrato complessivamente più accurato rispetto a \textit{XGBoost}.
Tale superiorità è risultata particolarmente evidente negli scenari multi-classe e in presenza di dataset sbilanciati (come \textit{octack} e \textit{apimds}), dove \textit{RandomForest} ha garantito una migliore generalizzazione,\
mantenendo valori alti di \fiscore{} anche sulle classi minoritarie, a differenza di \textit{XGBoost}.

In sintesi, il sistema sviluppato ha dimostrato la capacità di identificare le minacce con precisione osservando il comportamento del software piuttosto che la sua struttura statica,\
superando così i limiti delle tecniche di offuscamento che affliggono l'analisi statica tradizionale.

\section{Sviluppi Futuri}

Sebbene le metriche di accuratezza e F1-score ottenute confermino la validità dell'approccio proposto, la gestione del \textit{Concept Drift} nelle moderne minacce informatiche impone un'evoluzione architetturale.
Nel presente lavoro, la separazione tra i set di training e testing ha garantito la robustezza statistica; tuttavia, il prossimo step logico prevede la costruzione di un \textbf{macro-dataset unificato} per mitigare il bias di selezione e migliorare la capacità di generalizzazione del modello su distribuzioni di dati "out-of-distribution".

L'integrazione di sorgenti eterogenee, pur necessaria, espone il sistema alla cosiddetta \textit{Curse of Dimensionality}: l'esplosione del vocabolario delle API genera matrici estremamente sparse.
Per ottimizzare il costo computazionale e prevenire l'overfitting, si rende imperativa l'applicazione di pipeline di riduzione della dimensionalità. L'uso della \textit{Principal Component Analysis} (PCA) per massimizzare la varianza spiegata, o di filtri basati sull'\textit{Information Gain} per valutare l'entropia, permetterà di proiettare i dati in uno spazio latente più compatto senza perdita significativa di contenuto informativo.

Sul fronte modellistico, il limite principale dell'approccio attuale risiede nell'assunzione di indipendenza delle feature tipica del \textit{Bag-of-Words}. Tale codifica, pur efficiente, appiattisce la dimensione temporale, rendendo il classificatore cieco alla causalità delle chiamate di sistema.
Per ovviare a ciò, si propone la transizione verso architetture di \textbf{Deep Learning} sequenziali.

Nello specifico, l'adozione di reti \textit{Long Short-Term Memory} (LSTM) o \textit{Gated Recurrent Units} (GRU) permetterebbe di gestire le dipendenze a lungo termine, risolvendo il problema del \textit{vanishing gradient} tipico delle RNN standard. Ancor più promettente risulta l'impiego di architetture basate su \textbf{Transformer} e meccanismi di \textit{Self-Attention}, in grado di pesare le relazioni contestuali tra le API indipendentemente dalla loro distanza posizionale.
Questo paradigma permetterebbe di rilevare attacchi di \textit{adversarial evasion} che, pur mantenendo statistiche di frequenza lecite, presentano pattern di esecuzione anomali.